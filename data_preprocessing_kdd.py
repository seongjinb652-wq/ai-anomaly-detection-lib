# ============================================
# ğŸ“Œ data_preprocessing_kdd.py
# ëª©ì : KDD Cup ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ë° í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
# - ë°ì´í„° ë¡œë“œ ë° ì»¬ëŸ¼ ì´ë¦„ ì§€ì •
# - ë¼ë²¨ ì¸ì½”ë”©(LabelEncoder)ìœ¼ë¡œ í´ë˜ìŠ¤ ë³€í™˜
# - ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”© ì²˜ë¦¬
# - ìˆ«ìí˜• ë³€ìˆ˜ì™€ ë²”ì£¼í˜• ë³€ìˆ˜ ê²°í•©
# - í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„í• 
# - ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì„ pickle íŒŒì¼ë¡œ ì €ì¥
# - ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì´ìƒ íƒì§€ ëª¨ë¸ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ì— í™œìš©
# ============================================

# Import libraries that will be needed for the lab

import xgboost as xgb
import numpy as np
from collections import OrderedDict
import gc
from glob import glob
import os
import pandas as pd
from copy import copy
from time import time
from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score,classification_report,roc_curve
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from timeit import default_timer
import matplotlib.pyplot as plt
import pickle

# Set the seed for numpy
np.random.seed(123)

# Display all columns of Pandas' dataframes by default
pd.set_option('display.max_columns', None)

data_path = './data/kddcup.data.corrected'

# 2nd
col_names = ["duration","protocol_type","service","flag","src_bytes","dst_bytes","land","wrong_fragment","urgent","hot","num_failed_logins","logged_in",
             "num_compromised","root_shell","su_attempted","num_root","num_file_creations","num_shells","num_access_files","num_outbound_cmds",
             "is_host_login","is_guest_login","count","srv_count","serror_rate","srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate",
             "diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count","dst_host_same_srv_rate","dst_host_diff_srv_rate",
             "dst_host_same_src_port_rate","dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate","dst_host_rerror_rate",
             "dst_host_srv_rerror_rate","label"]

df =  pd.read_csv(data_path, header=None, names=col_names, index_col=False)

# Display the first few rows of the dataset
df.head(5)

# 3rd
pd.DataFrame(df['label'].value_counts())

# here we train a label encoder so that we can map our classes to integers later for model training
le = LabelEncoder()
le.fit(df.label)
print(le.classes_)

# 4th
# capture the categorical variables and one-hot encode them
cat_vars = ['protocol_type', 'service', 'flag', 'land', 'logged_in','is_host_login', 'is_guest_login']

# find unique labels for each category
cat_data = pd.get_dummies(df[cat_vars])

# check that the categorical variables were created correctly
cat_data.head()

# 5th
numeric_vars = list(set(df.columns.values.tolist()) - set(cat_vars))
numeric_vars.remove('label')
numeric_data = df[numeric_vars].copy()

# check that the numeric data has been captured accurately
numeric_data.head()

# concat numeric and the encoded categorical variables
numeric_cat_data = pd.concat([numeric_data, cat_data], axis=1)

# here we do a quick sanity check that the data has been concatenated correctly by checking the dimension of the vectors
print(cat_data.shape)
print(numeric_data.shape)
print(numeric_cat_data.shape)

# 6th
# capture the labels
labels = df['label'].copy()

# convert labels to integers
integer_labels = le.transform(labels)

# split data into test and train
x_train, x_test, y_train, y_test = train_test_split(numeric_cat_data,
                                                    integer_labels,
                                                    test_size=.25, 
                                                    random_state=42)

# check that the dimensions of our train and test sets are okay
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# save the datasets for later use
preprocessed_data = {
    'x_train':x_train,
    'y_train':y_train,
    'x_test':x_test,
    'y_test':y_test,
    'le':le
}

# pickle the preprocessed_data
path = 'preprocessed_data_full.pkl'
out = open(path, 'wb')
pickle.dump(preprocessed_data, out)
out.close()
